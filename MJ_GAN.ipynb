{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721264b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2178c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_MJ(x):\n",
    "   \n",
    "    accept = []\n",
    "    T = 1\n",
    "\n",
    "    X_accept = []\n",
    "    y_reject = []\n",
    "\n",
    "    X = np.random.rand(10*x,4)\n",
    "    #print(X)\n",
    "    \n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        \n",
    "    \n",
    "            \n",
    "                \n",
    "            \n",
    "            u = T*(-np.log(X[i,0]) - np.log(X[i,1]) - np.log(X[i,2]))\n",
    "            if X[i,3] < math.exp((u - math.sqrt(1+(u**2)))/T) and len(accept)<x:\n",
    "\n",
    "\n",
    "                number = u.tolist()\n",
    "                \n",
    "                accept.append(number-0.3)\n",
    "                #print(len(accept))\n",
    "                \n",
    "    accept = torch.Tensor(accept)\n",
    "    accept = accept.reshape(1,-1)\n",
    "    accept = accept\n",
    "        \n",
    "                \n",
    "    return accept.requires_grad_()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5b7c55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Series_Length = 30\n",
    "g_input_size = 20    \n",
    "g_hidden_size = 150  \n",
    "g_output_size = Series_Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5289ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_input_size = Series_Length\n",
    "d_hidden_size = 75  \n",
    "d_output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fc878bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_minibatch_size = 15 \n",
    "g_minibatch_size = 10\n",
    "\n",
    "num_epochs = 600000\n",
    "print_interval = 100\n",
    "\n",
    "d_learning_rate = 3e-3\n",
    "g_learning_rate = 8e-3\n",
    "\n",
    "def get_real_sampler(mu, sigma):\n",
    "    dist = Normal( mu, sigma )\n",
    "    return lambda m, n: dist.sample( (m, n) ).requires_grad_()\n",
    "\n",
    "def get_noise_sampler():\n",
    "    return lambda m, n: torch.rand(m, n).requires_grad_()  # Uniform-dist data into generator, _NOT_ Gaussian\n",
    "\n",
    "#actual_data = get_real_sampler( data_mean, data_stddev )\n",
    "noise_data  = get_noise_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6ff0c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map4 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.map5 = nn.Linear(hidden_size, output_size)\n",
    "              \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        self.xfer = torch.nn.SELU()\n",
    "        self.xfer_2 = torch.nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.xfer( self.map1(x) )\n",
    "        x = self.xfer( self.map2(x) )\n",
    "        x = self.xfer( self.map3(x) )\n",
    "        x = self.xfer( self.map4(x) )\n",
    "        \n",
    "      \n",
    "     \n",
    "       \n",
    "        \n",
    "    \n",
    "        return self.xfer( self.map5( x ) )\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        \n",
    "        self.map4 = nn.Linear(hidden_size, output_size)\n",
    "        self.elu = torch.nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.map1(x))\n",
    "        x = self.elu(self.map2(x))\n",
    "        x = self.elu(self.map3(x))\n",
    "        \n",
    "        \n",
    "        return torch.sigmoid( self.map4(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "73907785",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2d653112",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate ) #, betas=optim_betas)\n",
    "g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate ) #, betas=optim_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "413851bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_D_on_actual() :\n",
    "    #real_data = actual_data( d_minibatch_size, d_input_size )\n",
    "    u = d_minibatch_size*d_input_size\n",
    "    actual_data = get_real_MJ(u)\n",
    "    \n",
    "    #real_data = actual_data(d_minibatch_size,d_input_size)\n",
    "    real_data = torch.Tensor(actual_data).reshape(d_minibatch_size,d_input_size)\n",
    "    decision = D( real_data )\n",
    "    error = criterion( decision, torch.ones( d_minibatch_size, 1 ))  # ones = true\n",
    "    error.backward() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "54a528bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_D_on_generated() :\n",
    "    noise = noise_data( d_minibatch_size, g_input_size )\n",
    "    fake_data = G( noise ) \n",
    "    decision = D( fake_data )\n",
    "    error = criterion( decision, torch.zeros( d_minibatch_size, 1 ))  # zeros = fake\n",
    "    error.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "28ac152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_G():\n",
    "    noise = noise_data( g_minibatch_size, g_input_size )\n",
    "    fake_data = G( noise )\n",
    "    fake_decision = D( fake_data )\n",
    "    error = criterion( fake_decision, torch.ones( g_minibatch_size, 1 ) )  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "    error.backward()\n",
    "    return error.item(), fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4d1efdb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    100. Loss 0.699\n",
      "Epoch    200. Loss 0.605\n",
      "Epoch    300. Loss 0.803\n",
      "Epoch    400. Loss 0.586\n",
      "Epoch    500. Loss 0.874\n",
      "Epoch    600. Loss 1.090\n",
      "Epoch    700. Loss 0.935\n",
      "Epoch    800. Loss 0.956\n",
      "Epoch    900. Loss 0.795\n",
      "Epoch   1000. Loss 0.649\n",
      "Epoch   1100. Loss 0.714\n",
      "Epoch   1200. Loss 0.689\n",
      "Epoch   1300. Loss 0.600\n",
      "Epoch   1400. Loss 0.901\n",
      "Epoch   1500. Loss 0.786\n",
      "Epoch   1600. Loss 0.678\n",
      "Epoch   1700. Loss 0.715\n",
      "Epoch   1800. Loss 0.808\n",
      "Epoch   1900. Loss 0.668\n",
      "Epoch   2000. Loss 0.736\n",
      "Epoch   2100. Loss 0.730\n",
      "Epoch   2200. Loss 0.654\n",
      "Epoch   2300. Loss 0.840\n",
      "Epoch   2400. Loss 0.730\n",
      "Epoch   2500. Loss 0.757\n",
      "Epoch   2600. Loss 0.765\n",
      "Epoch   2700. Loss 0.768\n",
      "Epoch   2800. Loss 0.635\n",
      "Epoch   2900. Loss 0.741\n",
      "Epoch   3000. Loss 0.847\n",
      "Epoch   3100. Loss 0.785\n",
      "Epoch   3200. Loss 0.611\n",
      "Epoch   3300. Loss 0.689\n",
      "Epoch   3400. Loss 0.705\n",
      "Epoch   3500. Loss 0.741\n",
      "Epoch   3600. Loss 0.779\n",
      "Epoch   3700. Loss 0.868\n",
      "Epoch   3800. Loss 0.559\n",
      "Epoch   3900. Loss 0.749\n",
      "Epoch   4000. Loss 0.807\n",
      "Epoch   4100. Loss 0.644\n",
      "Epoch   4200. Loss 0.797\n",
      "Epoch   4300. Loss 0.829\n",
      "Epoch   4400. Loss 0.767\n",
      "Epoch   4500. Loss 0.749\n",
      "Epoch   4600. Loss 0.680\n",
      "Epoch   4700. Loss 0.696\n",
      "Epoch   4800. Loss 0.861\n",
      "Epoch   4900. Loss 0.937\n",
      "Epoch   5000. Loss 0.687\n",
      "Epoch   5100. Loss 0.726\n",
      "Epoch   5200. Loss 0.846\n",
      "Epoch   5300. Loss 0.720\n",
      "Epoch   5400. Loss 0.736\n",
      "Epoch   5500. Loss 0.839\n",
      "Epoch   5600. Loss 0.866\n",
      "Epoch   5700. Loss 0.807\n",
      "Epoch   5800. Loss 0.718\n",
      "Epoch   5900. Loss 0.858\n",
      "Epoch   6000. Loss 0.919\n",
      "Epoch   6100. Loss 0.774\n",
      "Epoch   6200. Loss 0.653\n",
      "Epoch   6300. Loss 0.847\n",
      "Epoch   6400. Loss 0.919\n",
      "Epoch   6500. Loss 0.743\n",
      "Epoch   6600. Loss 0.653\n",
      "Epoch   6700. Loss 0.774\n",
      "Epoch   6800. Loss 0.887\n",
      "Epoch   6900. Loss 0.671\n",
      "Epoch   7000. Loss 0.806\n",
      "Epoch   7100. Loss 0.755\n",
      "Epoch   7200. Loss 0.816\n",
      "Epoch   7300. Loss 0.749\n",
      "Epoch   7400. Loss 0.647\n",
      "Epoch   7500. Loss 0.730\n",
      "Epoch   7600. Loss 1.085\n",
      "Epoch   7700. Loss 0.848\n",
      "Epoch   7800. Loss 0.742\n",
      "Epoch   7900. Loss 0.930\n",
      "Epoch   8000. Loss 0.832\n",
      "Epoch   8100. Loss 0.781\n",
      "Epoch   8200. Loss 0.789\n",
      "Epoch   8300. Loss 0.964\n",
      "Epoch   8400. Loss 1.002\n",
      "Epoch   8500. Loss 0.718\n",
      "Epoch   8600. Loss 0.915\n",
      "Epoch   8700. Loss 0.991\n",
      "Epoch   8800. Loss 0.866\n",
      "Epoch   8900. Loss 0.671\n",
      "Epoch   9000. Loss 0.968\n",
      "Epoch   9100. Loss 0.751\n",
      "Epoch   9200. Loss 0.846\n",
      "Epoch   9300. Loss 0.834\n",
      "Epoch   9400. Loss 0.692\n",
      "Epoch   9500. Loss 0.906\n",
      "Epoch   9600. Loss 0.814\n",
      "Epoch   9700. Loss 0.638\n",
      "Epoch   9800. Loss 1.184\n",
      "Epoch   9900. Loss 0.724\n",
      "Epoch  10000. Loss 0.825\n",
      "Epoch  10100. Loss 0.739\n",
      "Epoch  10200. Loss 1.137\n",
      "Epoch  10300. Loss 0.859\n",
      "Epoch  10400. Loss 0.931\n",
      "Epoch  10500. Loss 0.933\n",
      "Epoch  10600. Loss 0.824\n",
      "Epoch  10700. Loss 0.742\n",
      "Epoch  10800. Loss 0.874\n",
      "Epoch  10900. Loss 0.715\n",
      "Epoch  11000. Loss 0.966\n",
      "Epoch  11100. Loss 0.779\n",
      "Epoch  11200. Loss 0.735\n",
      "Epoch  11300. Loss 0.675\n",
      "Epoch  11400. Loss 0.923\n",
      "Epoch  11500. Loss 0.850\n",
      "Epoch  11600. Loss 0.908\n",
      "Epoch  11700. Loss 1.017\n",
      "Epoch  11800. Loss 0.762\n",
      "Epoch  11900. Loss 0.820\n",
      "Epoch  12000. Loss 1.064\n",
      "Epoch  12100. Loss 0.648\n",
      "Epoch  12200. Loss 0.761\n",
      "Epoch  12300. Loss 0.819\n",
      "Epoch  12400. Loss 0.581\n",
      "Epoch  12500. Loss 0.820\n",
      "Epoch  12600. Loss 1.004\n",
      "Epoch  12700. Loss 1.065\n",
      "Epoch  12800. Loss 1.090\n",
      "Epoch  12900. Loss 0.715\n",
      "Epoch  13000. Loss 0.841\n",
      "Epoch  13100. Loss 1.005\n",
      "Epoch  13200. Loss 0.762\n",
      "Epoch  13300. Loss 1.108\n",
      "Epoch  13400. Loss 0.745\n",
      "Epoch  13500. Loss 0.851\n",
      "Epoch  13600. Loss 1.063\n",
      "Epoch  13700. Loss 0.918\n",
      "Epoch  13800. Loss 0.960\n",
      "Epoch  13900. Loss 0.699\n",
      "Epoch  14000. Loss 0.887\n",
      "Epoch  14100. Loss 0.779\n",
      "Epoch  14200. Loss 0.797\n",
      "Epoch  14300. Loss 0.819\n",
      "Epoch  14400. Loss 0.956\n",
      "Epoch  14500. Loss 1.144\n",
      "Epoch  14600. Loss 1.172\n",
      "Epoch  14700. Loss 0.905\n",
      "Epoch  14800. Loss 0.852\n",
      "Epoch  14900. Loss 0.875\n",
      "Epoch  15000. Loss 0.867\n",
      "Epoch  15100. Loss 0.860\n",
      "Epoch  15200. Loss 0.867\n",
      "Epoch  15300. Loss 0.827\n",
      "Epoch  15400. Loss 0.881\n",
      "Epoch  15500. Loss 0.886\n",
      "Epoch  15600. Loss 0.980\n",
      "Epoch  15700. Loss 0.928\n",
      "Epoch  15800. Loss 0.718\n",
      "Epoch  15900. Loss 1.171\n",
      "Epoch  16000. Loss 1.163\n",
      "Epoch  16100. Loss 0.755\n",
      "Epoch  16200. Loss 0.956\n",
      "Epoch  16300. Loss 0.659\n",
      "Epoch  16400. Loss 0.765\n",
      "Epoch  16500. Loss 0.804\n",
      "Epoch  16600. Loss 0.918\n",
      "Epoch  16700. Loss 0.840\n",
      "Epoch  16800. Loss 1.185\n",
      "Epoch  16900. Loss 0.679\n",
      "Epoch  17000. Loss 0.978\n",
      "Epoch  17100. Loss 1.079\n",
      "Epoch  17200. Loss 1.558\n",
      "Epoch  17300. Loss 0.998\n",
      "Epoch  17400. Loss 0.654\n",
      "Epoch  17500. Loss 0.999\n",
      "Epoch  17600. Loss 1.000\n",
      "Epoch  17700. Loss 1.967\n",
      "Epoch  17800. Loss 2.578\n",
      "Epoch  17900. Loss 2.990\n",
      "Epoch  18000. Loss 3.297\n",
      "Epoch  18100. Loss 3.534\n",
      "Epoch  18200. Loss 3.738\n",
      "Epoch  18300. Loss 3.922\n",
      "Epoch  18400. Loss 4.085\n",
      "Epoch  18500. Loss 4.228\n",
      "Epoch  18600. Loss 4.354\n",
      "Epoch  18700. Loss 4.466\n",
      "Epoch  18800. Loss 4.570\n",
      "Epoch  18900. Loss 4.668\n",
      "Epoch  19000. Loss 4.760\n",
      "Epoch  19100. Loss 4.844\n",
      "Epoch  19200. Loss 4.925\n",
      "Epoch  19300. Loss 4.999\n",
      "Epoch  19400. Loss 5.069\n",
      "Epoch  19500. Loss 5.130\n",
      "Epoch  19600. Loss 5.190\n",
      "Epoch  19700. Loss 5.250\n",
      "Epoch  19800. Loss 5.306\n",
      "Epoch  19900. Loss 5.360\n",
      "Epoch  20000. Loss 5.412\n",
      "Epoch  20100. Loss 5.462\n",
      "Epoch  20200. Loss 5.510\n",
      "Epoch  20300. Loss 5.557\n",
      "Epoch  20400. Loss 5.601\n",
      "Epoch  20500. Loss 5.644\n",
      "Epoch  20600. Loss 5.685\n",
      "Epoch  20700. Loss 5.726\n",
      "Epoch  20800. Loss 5.764\n",
      "Epoch  20900. Loss 5.802\n",
      "Epoch  21000. Loss 5.839\n",
      "Epoch  21100. Loss 5.874\n",
      "Epoch  21200. Loss 5.909\n",
      "Epoch  21300. Loss 5.942\n",
      "Epoch  21400. Loss 5.975\n",
      "Epoch  21500. Loss 6.007\n",
      "Epoch  21600. Loss 6.038\n",
      "Epoch  21700. Loss 6.068\n",
      "Epoch  21800. Loss 6.097\n",
      "Epoch  21900. Loss 6.126\n",
      "Epoch  22000. Loss 6.155\n",
      "Epoch  22100. Loss 6.182\n",
      "Epoch  22200. Loss 6.209\n",
      "Epoch  22300. Loss 6.235\n",
      "Epoch  22400. Loss 6.261\n",
      "Epoch  22500. Loss 6.286\n",
      "Epoch  22600. Loss 6.311\n",
      "Epoch  22700. Loss 6.335\n",
      "Epoch  22800. Loss 6.358\n",
      "Epoch  22900. Loss 6.382\n",
      "Epoch  23000. Loss 6.405\n",
      "Epoch  23100. Loss 6.427\n",
      "Epoch  23200. Loss 6.449\n",
      "Epoch  23300. Loss 6.471\n",
      "Epoch  23400. Loss 6.492\n",
      "Epoch  23500. Loss 6.513\n",
      "Epoch  23600. Loss 6.533\n",
      "Epoch  23700. Loss 6.553\n",
      "Epoch  23800. Loss 6.573\n",
      "Epoch  23900. Loss 6.593\n",
      "Epoch  24000. Loss 6.612\n",
      "Epoch  24100. Loss 6.631\n",
      "Epoch  24200. Loss 6.649\n",
      "Epoch  24300. Loss 6.668\n",
      "Epoch  24400. Loss 6.686\n",
      "Epoch  24500. Loss 6.704\n",
      "Epoch  24600. Loss 6.721\n",
      "Epoch  24700. Loss 6.738\n",
      "Epoch  24800. Loss 6.755\n",
      "Epoch  24900. Loss 6.772\n",
      "Epoch  25000. Loss 6.789\n",
      "Epoch  25100. Loss 6.805\n",
      "Epoch  25200. Loss 6.821\n",
      "Epoch  25300. Loss 6.837\n",
      "Epoch  25400. Loss 6.853\n",
      "Epoch  25500. Loss 6.868\n",
      "Epoch  25600. Loss 6.883\n",
      "Epoch  25700. Loss 6.898\n",
      "Epoch  25800. Loss 6.913\n",
      "Epoch  25900. Loss 6.928\n",
      "Epoch  26000. Loss 6.943\n",
      "Epoch  26100. Loss 6.957\n",
      "Epoch  26200. Loss 6.971\n",
      "Epoch  26300. Loss 6.985\n",
      "Epoch  26400. Loss 6.999\n",
      "Epoch  26500. Loss 7.013\n",
      "Epoch  26600. Loss 7.026\n",
      "Epoch  26700. Loss 7.040\n",
      "Epoch  26800. Loss 7.053\n",
      "Epoch  26900. Loss 7.066\n",
      "Epoch  27000. Loss 7.079\n",
      "Epoch  27100. Loss 7.092\n",
      "Epoch  27200. Loss 7.105\n",
      "Epoch  27300. Loss 7.117\n",
      "Epoch  27400. Loss 7.130\n",
      "Epoch  27500. Loss 7.142\n",
      "Epoch  27600. Loss 7.154\n",
      "Epoch  27700. Loss 7.166\n",
      "Epoch  27800. Loss 7.178\n",
      "Epoch  27900. Loss 7.190\n",
      "Epoch  28000. Loss 7.202\n",
      "Epoch  28100. Loss 7.213\n",
      "Epoch  28200. Loss 7.225\n",
      "Epoch  28300. Loss 7.236\n",
      "Epoch  28400. Loss 7.247\n",
      "Epoch  28500. Loss 7.258\n",
      "Epoch  28600. Loss 7.269\n",
      "Epoch  28700. Loss 7.280\n",
      "Epoch  28800. Loss 7.291\n",
      "Epoch  28900. Loss 7.302\n",
      "Epoch  29000. Loss 7.313\n",
      "Epoch  29100. Loss 7.323\n",
      "Epoch  29200. Loss 7.334\n",
      "Epoch  29300. Loss 7.344\n",
      "Epoch  29400. Loss 7.354\n",
      "Epoch  29500. Loss 7.364\n",
      "Epoch  29600. Loss 7.374\n",
      "Epoch  29700. Loss 7.385\n",
      "Epoch  29800. Loss 7.394\n",
      "Epoch  29900. Loss 7.404\n",
      "Epoch  30000. Loss 7.414\n",
      "Epoch  30100. Loss 7.424\n",
      "Epoch  30200. Loss 7.433\n",
      "Epoch  30300. Loss 7.443\n",
      "Epoch  30400. Loss 7.452\n",
      "Epoch  30500. Loss 7.462\n",
      "Epoch  30600. Loss 7.471\n",
      "Epoch  30700. Loss 7.480\n",
      "Epoch  30800. Loss 7.489\n",
      "Epoch  30900. Loss 7.499\n",
      "Epoch  31000. Loss 7.508\n",
      "Epoch  31100. Loss 7.517\n",
      "Epoch  31200. Loss 7.525\n",
      "Epoch  31300. Loss 7.534\n",
      "Epoch  31400. Loss 7.543\n",
      "Epoch  31500. Loss 7.552\n",
      "Epoch  31600. Loss 7.560\n",
      "Epoch  31700. Loss 7.569\n",
      "Epoch  31800. Loss 7.577\n",
      "Epoch  31900. Loss 7.586\n",
      "Epoch  32000. Loss 7.594\n",
      "Epoch  32100. Loss 7.603\n",
      "Epoch  32200. Loss 7.611\n",
      "Epoch  32300. Loss 7.619\n",
      "Epoch  32400. Loss 7.627\n",
      "Epoch  32500. Loss 7.635\n",
      "Epoch  32600. Loss 7.643\n",
      "Epoch  32700. Loss 7.651\n",
      "Epoch  32800. Loss 7.659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  32900. Loss 7.667\n",
      "Epoch  33000. Loss 7.675\n",
      "Epoch  33100. Loss 7.683\n",
      "Epoch  33200. Loss 7.691\n",
      "Epoch  33300. Loss 7.698\n",
      "Epoch  33400. Loss 7.706\n",
      "Epoch  33500. Loss 7.713\n",
      "Epoch  33600. Loss 7.721\n",
      "Epoch  33700. Loss 7.729\n",
      "Epoch  33800. Loss 7.736\n",
      "Epoch  33900. Loss 7.743\n",
      "Epoch  34000. Loss 7.751\n",
      "Epoch  34100. Loss 7.758\n",
      "Epoch  34200. Loss 7.765\n",
      "Epoch  34300. Loss 7.773\n",
      "Epoch  34400. Loss 7.780\n",
      "Epoch  34500. Loss 7.787\n",
      "Epoch  34600. Loss 7.794\n",
      "Epoch  34700. Loss 7.801\n",
      "Epoch  34800. Loss 7.808\n",
      "Epoch  34900. Loss 7.815\n",
      "Epoch  35000. Loss 7.822\n",
      "Epoch  35100. Loss 7.829\n",
      "Epoch  35200. Loss 7.836\n",
      "Epoch  35300. Loss 7.842\n",
      "Epoch  35400. Loss 7.849\n",
      "Epoch  35500. Loss 7.856\n",
      "Epoch  35600. Loss 7.863\n",
      "Epoch  35700. Loss 7.869\n",
      "Epoch  35800. Loss 7.876\n",
      "Epoch  35900. Loss 7.882\n",
      "Epoch  36000. Loss 7.889\n",
      "Epoch  36100. Loss 7.895\n",
      "Epoch  36200. Loss 7.902\n",
      "Epoch  36300. Loss 7.908\n",
      "Epoch  36400. Loss 7.915\n",
      "Epoch  36500. Loss 7.921\n",
      "Epoch  36600. Loss 7.927\n",
      "Epoch  36700. Loss 7.934\n",
      "Epoch  36800. Loss 7.940\n",
      "Epoch  36900. Loss 7.946\n",
      "Epoch  37000. Loss 7.952\n",
      "Epoch  37100. Loss 7.958\n",
      "Epoch  37200. Loss 7.965\n",
      "Epoch  37300. Loss 7.971\n",
      "Epoch  37400. Loss 7.977\n",
      "Epoch  37500. Loss 7.983\n",
      "Epoch  37600. Loss 7.989\n",
      "Epoch  37700. Loss 7.995\n",
      "Epoch  37800. Loss 8.001\n",
      "Epoch  37900. Loss 8.007\n",
      "Epoch  38000. Loss 8.013\n",
      "Epoch  38100. Loss 8.018\n",
      "Epoch  38200. Loss 8.024\n",
      "Epoch  38300. Loss 8.030\n",
      "Epoch  38400. Loss 8.036\n",
      "Epoch  38500. Loss 8.042\n",
      "Epoch  38600. Loss 8.047\n",
      "Epoch  38700. Loss 8.053\n",
      "Epoch  38800. Loss 8.059\n",
      "Epoch  38900. Loss 8.064\n",
      "Epoch  39000. Loss 8.070\n",
      "Epoch  39100. Loss 8.075\n",
      "Epoch  39200. Loss 8.081\n",
      "Epoch  39300. Loss 8.086\n",
      "Epoch  39400. Loss 8.092\n",
      "Epoch  39500. Loss 8.097\n",
      "Epoch  39600. Loss 8.103\n",
      "Epoch  39700. Loss 8.108\n",
      "Epoch  39800. Loss 8.114\n",
      "Epoch  39900. Loss 8.119\n",
      "Epoch  40000. Loss 8.124\n",
      "Epoch  40100. Loss 8.130\n",
      "Epoch  40200. Loss 8.135\n",
      "Epoch  40300. Loss 8.140\n",
      "Epoch  40400. Loss 8.146\n",
      "Epoch  40500. Loss 8.151\n",
      "Epoch  40600. Loss 8.156\n",
      "Epoch  40700. Loss 8.161\n",
      "Epoch  40800. Loss 8.166\n",
      "Epoch  40900. Loss 8.171\n",
      "Epoch  41000. Loss 8.177\n",
      "Epoch  41100. Loss 8.182\n",
      "Epoch  41200. Loss 8.187\n",
      "Epoch  41300. Loss 8.192\n",
      "Epoch  41400. Loss 8.197\n",
      "Epoch  41500. Loss 8.202\n",
      "Epoch  41600. Loss 8.207\n",
      "Epoch  41700. Loss 8.212\n",
      "Epoch  41800. Loss 8.217\n",
      "Epoch  41900. Loss 8.222\n",
      "Epoch  42000. Loss 8.227\n",
      "Epoch  42100. Loss 8.231\n",
      "Epoch  42200. Loss 8.236\n",
      "Epoch  42300. Loss 8.241\n",
      "Epoch  42400. Loss 8.246\n",
      "Epoch  42500. Loss 8.251\n",
      "Epoch  42600. Loss 8.256\n",
      "Epoch  42700. Loss 8.260\n",
      "Epoch  42800. Loss 8.265\n",
      "Epoch  42900. Loss 8.270\n",
      "Epoch  43000. Loss 8.274\n",
      "Epoch  43100. Loss 8.279\n",
      "Epoch  43200. Loss 8.284\n",
      "Epoch  43300. Loss 8.288\n",
      "Epoch  43400. Loss 8.293\n",
      "Epoch  43500. Loss 8.298\n",
      "Epoch  43600. Loss 8.302\n",
      "Epoch  43700. Loss 8.307\n",
      "Epoch  43800. Loss 8.312\n",
      "Epoch  43900. Loss 8.316\n",
      "Epoch  44000. Loss 8.321\n",
      "Epoch  44100. Loss 8.325\n",
      "Epoch  44200. Loss 8.330\n",
      "Epoch  44300. Loss 8.334\n",
      "Epoch  44400. Loss 8.338\n",
      "Epoch  44500. Loss 8.343\n",
      "Epoch  44600. Loss 8.347\n",
      "Epoch  44700. Loss 8.352\n",
      "Epoch  44800. Loss 8.356\n",
      "Epoch  44900. Loss 8.361\n",
      "Epoch  45000. Loss 8.365\n",
      "Epoch  45100. Loss 8.369\n",
      "Epoch  45200. Loss 8.374\n",
      "Epoch  45300. Loss 8.378\n",
      "Epoch  45400. Loss 8.382\n",
      "Epoch  45500. Loss 8.386\n",
      "Epoch  45600. Loss 8.391\n",
      "Epoch  45700. Loss 8.395\n",
      "Epoch  45800. Loss 8.399\n",
      "Epoch  45900. Loss 8.403\n",
      "Epoch  46000. Loss 8.408\n",
      "Epoch  46100. Loss 8.412\n",
      "Epoch  46200. Loss 8.416\n",
      "Epoch  46300. Loss 8.420\n",
      "Epoch  46400. Loss 8.424\n",
      "Epoch  46500. Loss 8.428\n",
      "Epoch  46600. Loss 8.433\n",
      "Epoch  46700. Loss 8.437\n",
      "Epoch  46800. Loss 8.441\n",
      "Epoch  46900. Loss 8.445\n",
      "Epoch  47000. Loss 8.449\n",
      "Epoch  47100. Loss 8.453\n",
      "Epoch  47200. Loss 8.457\n",
      "Epoch  47300. Loss 8.461\n",
      "Epoch  47400. Loss 8.465\n",
      "Epoch  47500. Loss 8.469\n",
      "Epoch  47600. Loss 8.473\n",
      "Epoch  47700. Loss 8.477\n",
      "Epoch  47800. Loss 8.481\n",
      "Epoch  47900. Loss 8.485\n",
      "Epoch  48000. Loss 8.489\n",
      "Epoch  48100. Loss 8.492\n",
      "Epoch  48200. Loss 8.496\n",
      "Epoch  48300. Loss 8.500\n",
      "Epoch  48400. Loss 8.504\n",
      "Epoch  48500. Loss 8.504\n",
      "Epoch  48600. Loss 8.506\n",
      "Epoch  48700. Loss 8.509\n",
      "Epoch  48800. Loss 8.512\n",
      "Epoch  48900. Loss 8.516\n",
      "Epoch  49000. Loss 8.520\n",
      "Epoch  49100. Loss 8.523\n",
      "Epoch  49200. Loss 8.527\n",
      "Epoch  49300. Loss 8.531\n",
      "Epoch  49400. Loss 8.535\n",
      "Epoch  49500. Loss 8.538\n",
      "Epoch  49600. Loss 8.542\n",
      "Epoch  49700. Loss 8.546\n",
      "Epoch  49800. Loss 8.549\n",
      "Epoch  49900. Loss 8.553\n",
      "Epoch  50000. Loss 8.556\n",
      "Epoch  50100. Loss 8.560\n",
      "Epoch  50200. Loss 8.564\n",
      "Epoch  50300. Loss 8.567\n",
      "Epoch  50400. Loss 8.571\n",
      "Epoch  50500. Loss 8.574\n",
      "Epoch  50600. Loss 8.578\n",
      "Epoch  50700. Loss 8.581\n",
      "Epoch  50800. Loss 8.585\n",
      "Epoch  50900. Loss 8.589\n",
      "Epoch  51000. Loss 8.592\n",
      "Epoch  51100. Loss 8.596\n",
      "Epoch  51200. Loss 8.599\n",
      "Epoch  51300. Loss 8.602\n",
      "Epoch  51400. Loss 8.606\n",
      "Epoch  51500. Loss 8.609\n",
      "Epoch  51600. Loss 8.613\n",
      "Epoch  51700. Loss 8.616\n",
      "Epoch  51800. Loss 8.620\n",
      "Epoch  51900. Loss 8.623\n",
      "Epoch  52000. Loss 8.627\n",
      "Epoch  52100. Loss 8.630\n",
      "Epoch  52200. Loss 8.633\n",
      "Epoch  52300. Loss 8.637\n",
      "Epoch  52400. Loss 8.640\n",
      "Epoch  52500. Loss 8.644\n",
      "Epoch  52600. Loss 8.647\n",
      "Epoch  52700. Loss 8.650\n",
      "Epoch  52800. Loss 8.654\n",
      "Epoch  52900. Loss 8.657\n",
      "Epoch  53000. Loss 8.660\n",
      "Epoch  53100. Loss 8.664\n",
      "Epoch  53200. Loss 8.667\n",
      "Epoch  53300. Loss 8.670\n",
      "Epoch  53400. Loss 8.673\n",
      "Epoch  53500. Loss 8.677\n",
      "Epoch  53600. Loss 8.680\n",
      "Epoch  53700. Loss 8.683\n",
      "Epoch  53800. Loss 8.686\n",
      "Epoch  53900. Loss 8.690\n",
      "Epoch  54000. Loss 8.693\n",
      "Epoch  54100. Loss 8.696\n",
      "Epoch  54200. Loss 8.699\n",
      "Epoch  54300. Loss 8.702\n",
      "Epoch  54400. Loss 8.706\n",
      "Epoch  54500. Loss 8.709\n",
      "Epoch  54600. Loss 8.712\n",
      "Epoch  54700. Loss 8.715\n",
      "Epoch  54800. Loss 8.718\n",
      "Epoch  54900. Loss 8.721\n",
      "Epoch  55000. Loss 8.725\n",
      "Epoch  55100. Loss 8.728\n",
      "Epoch  55200. Loss 8.731\n",
      "Epoch  55300. Loss 8.734\n",
      "Epoch  55400. Loss 8.737\n",
      "Epoch  55500. Loss 8.740\n",
      "Epoch  55600. Loss 8.743\n",
      "Epoch  55700. Loss 8.746\n",
      "Epoch  55800. Loss 8.749\n",
      "Epoch  55900. Loss 8.752\n",
      "Epoch  56000. Loss 8.755\n",
      "Epoch  56100. Loss 8.759\n",
      "Epoch  56200. Loss 8.762\n",
      "Epoch  56300. Loss 8.765\n",
      "Epoch  56400. Loss 8.768\n",
      "Epoch  56500. Loss 8.771\n",
      "Epoch  56600. Loss 8.774\n",
      "Epoch  56700. Loss 8.777\n",
      "Epoch  56800. Loss 8.780\n",
      "Epoch  56900. Loss 8.783\n",
      "Epoch  57000. Loss 8.786\n",
      "Epoch  57100. Loss 8.789\n",
      "Epoch  57200. Loss 8.792\n",
      "Epoch  57300. Loss 8.794\n",
      "Epoch  57400. Loss 8.797\n",
      "Epoch  57500. Loss 8.800\n",
      "Epoch  57600. Loss 8.803\n",
      "Epoch  57700. Loss 8.806\n",
      "Epoch  57800. Loss 8.809\n",
      "Epoch  57900. Loss 8.812\n",
      "Epoch  58000. Loss 8.815\n",
      "Epoch  58100. Loss 8.818\n",
      "Epoch  58200. Loss 8.821\n",
      "Epoch  58300. Loss 8.824\n",
      "Epoch  58400. Loss 8.827\n",
      "Epoch  58500. Loss 8.829\n",
      "Epoch  58600. Loss 8.832\n",
      "Epoch  58700. Loss 8.835\n",
      "Epoch  58800. Loss 8.838\n",
      "Epoch  58900. Loss 8.841\n",
      "Epoch  59000. Loss 8.844\n",
      "Epoch  59100. Loss 8.846\n",
      "Epoch  59200. Loss 8.849\n",
      "Epoch  59300. Loss 8.852\n",
      "Epoch  59400. Loss 8.855\n",
      "Epoch  59500. Loss 8.858\n",
      "Epoch  59600. Loss 8.861\n",
      "Epoch  59700. Loss 8.863\n",
      "Epoch  59800. Loss 8.866\n",
      "Epoch  59900. Loss 8.869\n",
      "Epoch  60000. Loss 8.872\n",
      "Epoch  60100. Loss 8.874\n",
      "Epoch  60200. Loss 8.877\n",
      "Epoch  60300. Loss 8.880\n",
      "Epoch  60400. Loss 8.883\n",
      "Epoch  60500. Loss 8.885\n",
      "Epoch  60600. Loss 8.888\n",
      "Epoch  60700. Loss 8.891\n",
      "Epoch  60800. Loss 8.894\n",
      "Epoch  60900. Loss 8.896\n",
      "Epoch  61000. Loss 8.899\n",
      "Epoch  61100. Loss 8.902\n",
      "Epoch  61200. Loss 8.904\n",
      "Epoch  61300. Loss 8.907\n",
      "Epoch  61400. Loss 8.910\n",
      "Epoch  61500. Loss 8.912\n",
      "Epoch  61600. Loss 8.915\n",
      "Epoch  61700. Loss 8.918\n",
      "Epoch  61800. Loss 8.920\n",
      "Epoch  61900. Loss 8.923\n",
      "Epoch  62000. Loss 8.926\n",
      "Epoch  62100. Loss 8.928\n",
      "Epoch  62200. Loss 8.931\n",
      "Epoch  62300. Loss 8.934\n",
      "Epoch  62400. Loss 8.936\n",
      "Epoch  62500. Loss 8.939\n",
      "Epoch  62600. Loss 8.941\n",
      "Epoch  62700. Loss 8.944\n",
      "Epoch  62800. Loss 8.947\n",
      "Epoch  62900. Loss 8.949\n",
      "Epoch  63000. Loss 8.952\n",
      "Epoch  63100. Loss 8.954\n",
      "Epoch  63200. Loss 8.957\n",
      "Epoch  63300. Loss 8.959\n",
      "Epoch  63400. Loss 8.962\n",
      "Epoch  63500. Loss 8.965\n",
      "Epoch  63600. Loss 8.967\n",
      "Epoch  63700. Loss 8.970\n",
      "Epoch  63800. Loss 8.972\n",
      "Epoch  63900. Loss 8.975\n",
      "Epoch  64000. Loss 8.977\n",
      "Epoch  64100. Loss 8.980\n",
      "Epoch  64200. Loss 8.982\n",
      "Epoch  64300. Loss 8.985\n",
      "Epoch  64400. Loss 8.987\n",
      "Epoch  64500. Loss 8.990\n",
      "Epoch  64600. Loss 8.992\n",
      "Epoch  64700. Loss 8.995\n",
      "Epoch  64800. Loss 8.997\n",
      "Epoch  64900. Loss 9.000\n",
      "Epoch  65000. Loss 9.002\n",
      "Epoch  65100. Loss 9.005\n",
      "Epoch  65200. Loss 9.007\n",
      "Epoch  65300. Loss 9.010\n",
      "Epoch  65400. Loss 9.012\n",
      "Epoch  65500. Loss 9.014\n",
      "Epoch  65600. Loss 9.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  65700. Loss 9.019\n",
      "Epoch  65800. Loss 9.022\n",
      "Epoch  65900. Loss 9.024\n",
      "Epoch  66000. Loss 9.027\n",
      "Epoch  66100. Loss 9.029\n",
      "Epoch  66200. Loss 9.032\n",
      "Epoch  66300. Loss 9.034\n",
      "Epoch  66400. Loss 9.036\n",
      "Epoch  66500. Loss 9.039\n",
      "Epoch  66600. Loss 9.041\n",
      "Epoch  66700. Loss 9.043\n",
      "Epoch  66800. Loss 9.046\n",
      "Epoch  66900. Loss 9.048\n",
      "Epoch  67000. Loss 9.051\n",
      "Epoch  67100. Loss 9.053\n",
      "Epoch  67200. Loss 9.055\n",
      "Epoch  67300. Loss 9.058\n",
      "Epoch  67400. Loss 9.060\n",
      "Epoch  67500. Loss 9.062\n",
      "Epoch  67600. Loss 9.065\n",
      "Epoch  67700. Loss 9.067\n",
      "Epoch  67800. Loss 9.069\n",
      "Epoch  67900. Loss 9.072\n",
      "Epoch  68000. Loss 9.074\n",
      "Epoch  68100. Loss 9.076\n",
      "Epoch  68200. Loss 9.079\n",
      "Epoch  68300. Loss 9.081\n",
      "Epoch  68400. Loss 9.083\n",
      "Epoch  68500. Loss 9.086\n",
      "Epoch  68600. Loss 9.088\n",
      "Epoch  68700. Loss 9.090\n",
      "Epoch  68800. Loss 9.093\n",
      "Epoch  68900. Loss 9.095\n",
      "Epoch  69000. Loss 9.097\n",
      "Epoch  69100. Loss 9.099\n",
      "Epoch  69200. Loss 9.102\n",
      "Epoch  69300. Loss 9.104\n",
      "Epoch  69400. Loss 9.106\n",
      "Epoch  69500. Loss 9.108\n",
      "Epoch  69600. Loss 9.111\n",
      "Epoch  69700. Loss 9.113\n",
      "Epoch  69800. Loss 9.115\n",
      "Epoch  69900. Loss 9.117\n",
      "Epoch  70000. Loss 9.120\n",
      "Epoch  70100. Loss 9.122\n",
      "Epoch  70200. Loss 9.124\n",
      "Epoch  70300. Loss 9.126\n",
      "Epoch  70400. Loss 9.129\n",
      "Epoch  70500. Loss 9.131\n",
      "Epoch  70600. Loss 9.133\n",
      "Epoch  70700. Loss 9.135\n",
      "Epoch  70800. Loss 9.137\n",
      "Epoch  70900. Loss 9.140\n",
      "Epoch  71000. Loss 9.142\n",
      "Epoch  71100. Loss 9.144\n",
      "Epoch  71200. Loss 9.146\n",
      "Epoch  71300. Loss 9.148\n",
      "Epoch  71400. Loss 9.150\n",
      "Epoch  71500. Loss 9.153\n",
      "Epoch  71600. Loss 9.155\n",
      "Epoch  71700. Loss 9.157\n",
      "Epoch  71800. Loss 9.159\n",
      "Epoch  71900. Loss 9.161\n",
      "Epoch  72000. Loss 9.163\n",
      "Epoch  72100. Loss 9.166\n",
      "Epoch  72200. Loss 9.168\n",
      "Epoch  72300. Loss 9.170\n",
      "Epoch  72400. Loss 9.172\n",
      "Epoch  72500. Loss 9.174\n",
      "Epoch  72600. Loss 9.176\n",
      "Epoch  72700. Loss 9.178\n",
      "Epoch  72800. Loss 9.180\n",
      "Epoch  72900. Loss 9.183\n",
      "Epoch  73000. Loss 9.185\n",
      "Epoch  73100. Loss 9.187\n",
      "Epoch  73200. Loss 9.189\n",
      "Epoch  73300. Loss 9.191\n",
      "Epoch  73400. Loss 9.193\n",
      "Epoch  73500. Loss 9.195\n",
      "Epoch  73600. Loss 9.197\n",
      "Epoch  73700. Loss 9.199\n",
      "Epoch  73800. Loss 9.202\n",
      "Epoch  73900. Loss 9.204\n",
      "Epoch  74000. Loss 9.206\n",
      "Epoch  74100. Loss 9.208\n",
      "Epoch  74200. Loss 9.210\n",
      "Epoch  74300. Loss 9.212\n",
      "Epoch  74400. Loss 9.214\n",
      "Epoch  74500. Loss 9.216\n",
      "Epoch  74600. Loss 9.218\n",
      "Epoch  74700. Loss 9.220\n",
      "Epoch  74800. Loss 9.222\n",
      "Epoch  74900. Loss 9.224\n",
      "Epoch  75000. Loss 9.226\n",
      "Epoch  75100. Loss 9.228\n",
      "Epoch  75200. Loss 9.230\n",
      "Epoch  75300. Loss 9.232\n",
      "Epoch  75400. Loss 9.234\n",
      "Epoch  75500. Loss 9.236\n",
      "Epoch  75600. Loss 9.238\n",
      "Epoch  75700. Loss 9.240\n",
      "Epoch  75800. Loss 9.242\n",
      "Epoch  75900. Loss 9.244\n",
      "Epoch  76000. Loss 9.246\n",
      "Epoch  76100. Loss 9.248\n",
      "Epoch  76200. Loss 9.250\n",
      "Epoch  76300. Loss 9.252\n",
      "Epoch  76400. Loss 9.254\n",
      "Epoch  76500. Loss 9.254\n",
      "Epoch  76600. Loss 9.238\n",
      "Epoch  76700. Loss 9.240\n",
      "Epoch  76800. Loss 9.242\n",
      "Epoch  76900. Loss 9.244\n",
      "Epoch  77000. Loss 9.246\n",
      "Epoch  77100. Loss 9.248\n",
      "Epoch  77200. Loss 9.250\n",
      "Epoch  77300. Loss 9.252\n",
      "Epoch  77400. Loss 9.254\n",
      "Epoch  77500. Loss 9.256\n",
      "Epoch  77600. Loss 9.258\n",
      "Epoch  77700. Loss 9.261\n",
      "Epoch  77800. Loss 9.262\n",
      "Epoch  77900. Loss 9.265\n",
      "Epoch  78000. Loss 9.267\n",
      "Epoch  78100. Loss 9.268\n",
      "Epoch  78200. Loss 9.270\n",
      "Epoch  78300. Loss 9.272\n",
      "Epoch  78400. Loss 9.274\n",
      "Epoch  78500. Loss 9.276\n",
      "Epoch  78600. Loss 9.278\n",
      "Epoch  78700. Loss 9.280\n",
      "Epoch  78800. Loss 9.282\n",
      "Epoch  78900. Loss 9.284\n",
      "Epoch  79000. Loss 9.286\n",
      "Epoch  79100. Loss 9.288\n",
      "Epoch  79200. Loss 9.290\n",
      "Epoch  79300. Loss 9.292\n",
      "Epoch  79400. Loss 9.294\n",
      "Epoch  79500. Loss 9.296\n",
      "Epoch  79600. Loss 9.298\n",
      "Epoch  79700. Loss 9.300\n",
      "Epoch  79800. Loss 9.302\n",
      "Epoch  79900. Loss 9.304\n",
      "Epoch  80000. Loss 9.306\n",
      "Epoch  80100. Loss 9.308\n",
      "Epoch  80200. Loss 9.310\n",
      "Epoch  80300. Loss 9.312\n",
      "Epoch  80400. Loss 9.313\n",
      "Epoch  80500. Loss 9.315\n",
      "Epoch  80600. Loss 9.317\n",
      "Epoch  80700. Loss 9.319\n",
      "Epoch  80800. Loss 9.321\n",
      "Epoch  80900. Loss 9.323\n",
      "Epoch  81000. Loss 9.325\n",
      "Epoch  81100. Loss 9.327\n",
      "Epoch  81200. Loss 9.329\n",
      "Epoch  81300. Loss 9.331\n",
      "Epoch  81400. Loss 9.333\n",
      "Epoch  81500. Loss 9.334\n",
      "Epoch  81600. Loss 9.336\n",
      "Epoch  81700. Loss 9.338\n",
      "Epoch  81800. Loss 9.340\n",
      "Epoch  81900. Loss 9.342\n",
      "Epoch  82000. Loss 9.344\n",
      "Epoch  82100. Loss 9.346\n",
      "Epoch  82200. Loss 9.348\n",
      "Epoch  82300. Loss 9.349\n",
      "Epoch  82400. Loss 9.351\n",
      "Epoch  82500. Loss 9.353\n",
      "Epoch  82600. Loss 9.355\n",
      "Epoch  82700. Loss 9.357\n",
      "Epoch  82800. Loss 9.359\n",
      "Epoch  82900. Loss 9.361\n",
      "Epoch  83000. Loss 9.362\n",
      "Epoch  83100. Loss 9.364\n",
      "Epoch  83200. Loss 9.366\n",
      "Epoch  83300. Loss 9.368\n",
      "Epoch  83400. Loss 9.370\n",
      "Epoch  83500. Loss 9.372\n",
      "Epoch  83600. Loss 9.373\n",
      "Epoch  83700. Loss 9.375\n",
      "Epoch  83800. Loss 9.377\n",
      "Epoch  83900. Loss 9.379\n",
      "Epoch  84000. Loss 9.381\n",
      "Epoch  84100. Loss 9.382\n",
      "Epoch  84200. Loss 9.384\n",
      "Epoch  84300. Loss 9.386\n",
      "Epoch  84400. Loss 9.388\n",
      "Epoch  84500. Loss 9.390\n",
      "Epoch  84600. Loss 9.391\n",
      "Epoch  84700. Loss 9.393\n",
      "Epoch  84800. Loss 9.395\n",
      "Epoch  84900. Loss 9.397\n",
      "Epoch  85000. Loss 9.399\n",
      "Epoch  85100. Loss 9.400\n",
      "Epoch  85200. Loss 9.402\n",
      "Epoch  85300. Loss 9.404\n",
      "Epoch  85400. Loss 9.406\n",
      "Epoch  85500. Loss 9.407\n",
      "Epoch  85600. Loss 9.409\n",
      "Epoch  85700. Loss 9.411\n",
      "Epoch  85800. Loss 9.413\n",
      "Epoch  85900. Loss 9.414\n",
      "Epoch  86000. Loss 9.416\n",
      "Epoch  86100. Loss 9.418\n",
      "Epoch  86200. Loss 9.420\n",
      "Epoch  86300. Loss 9.421\n",
      "Epoch  86400. Loss 9.423\n",
      "Epoch  86500. Loss 9.425\n",
      "Epoch  86600. Loss 9.427\n",
      "Epoch  86700. Loss 9.428\n",
      "Epoch  86800. Loss 9.430\n",
      "Epoch  86900. Loss 9.432\n",
      "Epoch  87000. Loss 9.434\n",
      "Epoch  87100. Loss 9.435\n",
      "Epoch  87200. Loss 9.437\n",
      "Epoch  87300. Loss 9.439\n",
      "Epoch  87400. Loss 9.441\n",
      "Epoch  87500. Loss 9.442\n",
      "Epoch  87600. Loss 9.444\n",
      "Epoch  87700. Loss 9.446\n",
      "Epoch  87800. Loss 9.447\n",
      "Epoch  87900. Loss 9.449\n",
      "Epoch  88000. Loss 9.451\n",
      "Epoch  88100. Loss 9.453\n",
      "Epoch  88200. Loss 9.454\n",
      "Epoch  88300. Loss 9.456\n",
      "Epoch  88400. Loss 9.458\n",
      "Epoch  88500. Loss 9.459\n",
      "Epoch  88600. Loss 9.461\n",
      "Epoch  88700. Loss 9.463\n",
      "Epoch  88800. Loss 9.464\n",
      "Epoch  88900. Loss 9.466\n",
      "Epoch  89000. Loss 9.468\n",
      "Epoch  89100. Loss 9.470\n",
      "Epoch  89200. Loss 9.471\n",
      "Epoch  89300. Loss 9.473\n",
      "Epoch  89400. Loss 9.475\n",
      "Epoch  89500. Loss 9.476\n",
      "Epoch  89600. Loss 9.478\n",
      "Epoch  89700. Loss 9.480\n",
      "Epoch  89800. Loss 9.481\n",
      "Epoch  89900. Loss 9.483\n",
      "Epoch  90000. Loss 9.485\n",
      "Epoch  90100. Loss 9.486\n",
      "Epoch  90200. Loss 9.488\n",
      "Epoch  90300. Loss 9.490\n",
      "Epoch  90400. Loss 9.491\n",
      "Epoch  90500. Loss 9.493\n",
      "Epoch  90600. Loss 9.494\n",
      "Epoch  90700. Loss 9.496\n",
      "Epoch  90800. Loss 9.498\n",
      "Epoch  90900. Loss 9.499\n",
      "Epoch  91000. Loss 9.501\n",
      "Epoch  91100. Loss 9.503\n",
      "Epoch  91200. Loss 9.504\n",
      "Epoch  91300. Loss 9.506\n",
      "Epoch  91400. Loss 9.508\n",
      "Epoch  91500. Loss 9.509\n",
      "Epoch  91600. Loss 9.511\n",
      "Epoch  91700. Loss 9.512\n",
      "Epoch  91800. Loss 9.514\n",
      "Epoch  91900. Loss 9.516\n",
      "Epoch  92000. Loss 9.517\n",
      "Epoch  92100. Loss 9.519\n",
      "Epoch  92200. Loss 9.520\n",
      "Epoch  92300. Loss 9.522\n",
      "Epoch  92400. Loss 9.524\n",
      "Epoch  92500. Loss 9.525\n",
      "Epoch  92600. Loss 9.527\n",
      "Epoch  92700. Loss 9.528\n",
      "Epoch  92800. Loss 9.530\n",
      "Epoch  92900. Loss 9.532\n",
      "Epoch  93000. Loss 9.533\n",
      "Epoch  93100. Loss 9.535\n",
      "Epoch  93200. Loss 9.536\n",
      "Epoch  93300. Loss 9.538\n",
      "Epoch  93400. Loss 9.540\n",
      "Epoch  93500. Loss 9.541\n",
      "Epoch  93600. Loss 9.543\n",
      "Epoch  93700. Loss 9.544\n",
      "Epoch  93800. Loss 9.546\n",
      "Epoch  93900. Loss 9.547\n",
      "Epoch  94000. Loss 9.549\n",
      "Epoch  94100. Loss 9.551\n",
      "Epoch  94200. Loss 9.552\n",
      "Epoch  94300. Loss 9.554\n",
      "Epoch  94400. Loss 9.555\n",
      "Epoch  94500. Loss 9.557\n",
      "Epoch  94600. Loss 9.558\n",
      "Epoch  94700. Loss 9.560\n",
      "Epoch  94800. Loss 9.561\n",
      "Epoch  94900. Loss 9.563\n",
      "Epoch  95000. Loss 9.565\n",
      "Epoch  95100. Loss 9.566\n",
      "Epoch  95200. Loss 9.568\n",
      "Epoch  95300. Loss 9.569\n",
      "Epoch  95400. Loss 9.571\n",
      "Epoch  95500. Loss 9.572\n",
      "Epoch  95600. Loss 9.574\n",
      "Epoch  95700. Loss 9.575\n",
      "Epoch  95800. Loss 9.577\n",
      "Epoch  95900. Loss 9.578\n",
      "Epoch  96000. Loss 9.580\n",
      "Epoch  96100. Loss 9.581\n",
      "Epoch  96200. Loss 9.583\n",
      "Epoch  96300. Loss 9.584\n",
      "Epoch  96400. Loss 9.586\n",
      "Epoch  96500. Loss 9.587\n",
      "Epoch  96600. Loss 9.589\n",
      "Epoch  96700. Loss 9.590\n",
      "Epoch  96800. Loss 9.592\n",
      "Epoch  96900. Loss 9.593\n",
      "Epoch  97000. Loss 9.595\n",
      "Epoch  97100. Loss 9.596\n",
      "Epoch  97200. Loss 9.598\n",
      "Epoch  97300. Loss 9.599\n",
      "Epoch  97400. Loss 9.601\n",
      "Epoch  97500. Loss 9.603\n",
      "Epoch  97600. Loss 9.604\n",
      "Epoch  97700. Loss 9.605\n",
      "Epoch  97800. Loss 9.607\n",
      "Epoch  97900. Loss 9.609\n",
      "Epoch  98000. Loss 9.610\n",
      "Epoch  98100. Loss 9.611\n",
      "Epoch  98200. Loss 9.613\n",
      "Epoch  98300. Loss 9.614\n",
      "Epoch  98400. Loss 9.616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  98500. Loss 9.617\n",
      "Epoch  98600. Loss 9.619\n",
      "Epoch  98700. Loss 9.620\n",
      "Epoch  98800. Loss 9.622\n",
      "Epoch  98900. Loss 9.623\n",
      "Epoch  99000. Loss 9.625\n",
      "Epoch  99100. Loss 9.626\n",
      "Epoch  99200. Loss 9.628\n",
      "Epoch  99300. Loss 9.629\n",
      "Epoch  99400. Loss 9.631\n",
      "Epoch  99500. Loss 9.632\n",
      "Epoch  99600. Loss 9.634\n",
      "Epoch  99700. Loss 9.635\n",
      "Epoch  99800. Loss 9.636\n",
      "Epoch  99900. Loss 9.638\n",
      "Epoch 100000. Loss 9.639\n",
      "Epoch 100100. Loss 9.641\n",
      "Epoch 100200. Loss 9.642\n",
      "Epoch 100300. Loss 9.644\n",
      "Epoch 100400. Loss 9.645\n",
      "Epoch 100500. Loss 9.647\n",
      "Epoch 100600. Loss 9.648\n",
      "Epoch 100700. Loss 9.649\n",
      "Epoch 100800. Loss 9.651\n",
      "Epoch 100900. Loss 9.652\n",
      "Epoch 101000. Loss 9.654\n",
      "Epoch 101100. Loss 9.655\n",
      "Epoch 101200. Loss 9.657\n",
      "Epoch 101300. Loss 9.658\n",
      "Epoch 101400. Loss 9.659\n",
      "Epoch 101500. Loss 9.661\n",
      "Epoch 101600. Loss 9.662\n",
      "Epoch 101700. Loss 9.664\n",
      "Epoch 101800. Loss 9.665\n",
      "Epoch 101900. Loss 9.667\n",
      "Epoch 102000. Loss 9.668\n",
      "Epoch 102100. Loss 9.669\n",
      "Epoch 102200. Loss 9.671\n",
      "Epoch 102300. Loss 9.672\n",
      "Epoch 102400. Loss 9.674\n",
      "Epoch 102500. Loss 9.675\n",
      "Epoch 102600. Loss 9.676\n",
      "Epoch 102700. Loss 9.678\n",
      "Epoch 102800. Loss 9.679\n",
      "Epoch 102900. Loss 9.681\n",
      "Epoch 103000. Loss 9.682\n",
      "Epoch 103100. Loss 9.683\n",
      "Epoch 103200. Loss 9.685\n",
      "Epoch 103300. Loss 9.686\n",
      "Epoch 103400. Loss 9.688\n",
      "Epoch 103500. Loss 9.689\n",
      "Epoch 103600. Loss 9.690\n",
      "Epoch 103700. Loss 9.692\n",
      "Epoch 103800. Loss 9.693\n",
      "Epoch 103900. Loss 9.694\n",
      "Epoch 104000. Loss 9.696\n",
      "Epoch 104100. Loss 9.697\n",
      "Epoch 104200. Loss 9.699\n",
      "Epoch 104300. Loss 9.700\n",
      "Epoch 104400. Loss 9.701\n",
      "Epoch 104500. Loss 9.703\n",
      "Epoch 104600. Loss 9.704\n",
      "Epoch 104700. Loss 9.705\n",
      "Epoch 104800. Loss 9.707\n",
      "Epoch 104900. Loss 9.708\n",
      "Epoch 105000. Loss 9.710\n",
      "Epoch 105100. Loss 9.711\n",
      "Epoch 105200. Loss 9.712\n",
      "Epoch 105300. Loss 9.714\n",
      "Epoch 105400. Loss 9.715\n",
      "Epoch 105500. Loss 9.716\n",
      "Epoch 105600. Loss 9.718\n",
      "Epoch 105700. Loss 9.719\n",
      "Epoch 105800. Loss 9.720\n",
      "Epoch 105900. Loss 9.722\n",
      "Epoch 106000. Loss 9.723\n",
      "Epoch 106100. Loss 9.724\n",
      "Epoch 106200. Loss 9.726\n",
      "Epoch 106300. Loss 9.727\n",
      "Epoch 106400. Loss 9.728\n",
      "Epoch 106500. Loss 9.730\n",
      "Epoch 106600. Loss 9.731\n",
      "Epoch 106700. Loss 9.733\n",
      "Epoch 106800. Loss 9.734\n",
      "Epoch 106900. Loss 9.735\n",
      "Epoch 107000. Loss 9.737\n",
      "Epoch 107100. Loss 9.738\n",
      "Epoch 107200. Loss 9.739\n",
      "Epoch 107300. Loss 9.740\n",
      "Epoch 107400. Loss 9.742\n",
      "Epoch 107500. Loss 9.743\n",
      "Epoch 107600. Loss 9.744\n",
      "Epoch 107700. Loss 9.746\n",
      "Epoch 107800. Loss 9.747\n",
      "Epoch 107900. Loss 9.748\n",
      "Epoch 108000. Loss 9.750\n",
      "Epoch 108100. Loss 9.751\n",
      "Epoch 108200. Loss 9.752\n",
      "Epoch 108300. Loss 9.754\n",
      "Epoch 108400. Loss 9.755\n",
      "Epoch 108500. Loss 9.756\n",
      "Epoch 108600. Loss 9.758\n",
      "Epoch 108700. Loss 9.759\n",
      "Epoch 108800. Loss 9.760\n",
      "Epoch 108900. Loss 9.761\n",
      "Epoch 109000. Loss 9.763\n",
      "Epoch 109100. Loss 9.764\n",
      "Epoch 109200. Loss 9.765\n",
      "Epoch 109300. Loss 9.767\n",
      "Epoch 109400. Loss 9.768\n",
      "Epoch 109500. Loss 9.769\n",
      "Epoch 109600. Loss 9.771\n",
      "Epoch 109700. Loss 9.772\n",
      "Epoch 109800. Loss 9.773\n",
      "Epoch 109900. Loss 9.774\n",
      "Epoch 110000. Loss 9.776\n",
      "Epoch 110100. Loss 9.777\n",
      "Epoch 110200. Loss 9.778\n",
      "Epoch 110300. Loss 9.780\n",
      "Epoch 110400. Loss 9.781\n",
      "Epoch 110500. Loss 9.782\n",
      "Epoch 110600. Loss 9.783\n",
      "Epoch 110700. Loss 9.785\n",
      "Epoch 110800. Loss 9.786\n",
      "Epoch 110900. Loss 9.787\n",
      "Epoch 111000. Loss 9.789\n",
      "Epoch 111100. Loss 9.790\n",
      "Epoch 111200. Loss 9.791\n",
      "Epoch 111300. Loss 9.792\n",
      "Epoch 111400. Loss 9.794\n",
      "Epoch 111500. Loss 9.795\n",
      "Epoch 111600. Loss 9.796\n",
      "Epoch 111700. Loss 9.797\n",
      "Epoch 111800. Loss 9.799\n",
      "Epoch 111900. Loss 9.800\n",
      "Epoch 112000. Loss 9.801\n",
      "Epoch 112100. Loss 9.802\n",
      "Epoch 112200. Loss 9.804\n",
      "Epoch 112300. Loss 9.805\n",
      "Epoch 112400. Loss 9.806\n",
      "Epoch 112500. Loss 9.808\n",
      "Epoch 112600. Loss 9.809\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-ed8612793222>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_D_on_actual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtrain_D_on_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0md_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-129-d83c648abc12>\u001b[0m in \u001b[0;36mtrain_D_on_actual\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#real_data = actual_data( d_minibatch_size, d_input_size )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_minibatch_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md_input_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mactual_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_MJ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#real_data = actual_data(d_minibatch_size,d_input_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-116-ef5c608f1ddc>\u001b[0m in \u001b[0;36mget_real_MJ\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    D.zero_grad()\n",
    "    \n",
    "    train_D_on_actual()    \n",
    "    train_D_on_generated()\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    G.zero_grad()\n",
    "    loss,generated = train_G()\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    losses.append( loss )\n",
    "    if( epoch % print_interval) == (print_interval-1) :\n",
    "        print( \"Epoch %6d. Loss %5.3f\" % ( epoch+1, loss ) )\n",
    "        \n",
    "print( \"Training complete\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8cefc6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generated_samples = []\n",
    "for i in range(10000):\n",
    "    noise = noise_data( g_minibatch_size, g_input_size )\n",
    "    fake_data = G( noise )\n",
    "    Generated_samples.append(fake_data.flatten().tolist())\n",
    "    \n",
    "TF = np.empty([10000,300])\n",
    "for i in range(len(Generated_samples)):\n",
    "    TF[i] = Generated_samples[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0d71ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = get_real_MJ(10000*300)\n",
    "v = torch.Tensor(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1601a885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.hist(v.tolist(),np.linspace(-2,10,100),alpha = 0.5, color = 'b', label = 'real data')\n",
    "pyplot.hist(JF.flatten()[JF.flatten()>-0.2],np.linspace(-2,10,100),np.linspace(-2,3,100),alpha = 0.5, color = 'y',label = 'generated data')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "aea41cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(JF.reshape(1,-1).tolist(),np.linspace(-2,10,100),alpha=0.5)\n",
    "plt.hist(v.tolist(),np.linspace(-2,10,100),alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ae0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "Z =   G.reshape(150,200)\n",
    "plt.imshow(Z, cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fd1f86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.runs import runstest_1samp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2c47215d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.84320927 5.05913782 3.00125432 ... 1.59787929 2.70986104 3.61600161]]\n"
     ]
    }
   ],
   "source": [
    "print(JF.flatten()[JF.flatten()>-0.2].reshape(1,-1)[:,:10000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
